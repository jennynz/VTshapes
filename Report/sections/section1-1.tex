\section{Speech technology}

Speech is bafflingly complex. \textit{Speech production} requires fine neurological and motor processes acting in concert, exploiting various physiological structures to transform airflow into precise sound waves. And yet, every human being is capable of producing fluent streams of mutually understandable utterances. \textit{Speech recognition} is equally astounding. Daily, we navigate endless variables such as tone, pitch, accent, and context with subconscious ease. We are able to easily understand a friend in a room full of noisy conversations; we instantly recognise speech in a language we know; we generally have no trouble understanding someone with a stammer or a lisp. Clearly, humans possess a formidable knack for producing and understanding these subtle, precise sound bites.

Unfortunately for computers, it isn't so easy. However, speech signal processing and the voice science is a growing area of research today, in response to the increased importance of speech technology in our world \cite{syntaxnet}. Improving speech recognition opens doors to the potential in the vast \textit{corpus} (i.e. dataset) of digitised human language available to us via the Internet, which in turn provides useful data for improving speech synthesis models. The applications are all around us, such as improving speech aids for the voice- or hearing-impaired; developing intuitive virtual assistants like Siri or a GPS unit; even in forensic speech science where voice recognition is used as evidence in court, or to build suspect profiles.

At the very high level, this project focuses on analysing and quantifying the effects of age and accent on vowels. A functional model of the \textit{vocal tract} (VT)\footnote{In articulatory phonetics, the vocal tract is essentially the mouth and throat, from the lips to the glottis where the vocal folds are situated.} which accounts for such factors in its speech recognition and production algorithms is likely to produce more accurate, realistic results. For example, in \textit{speech synthesis}, the standard approach even today consists of stringing together recorded speech segments as needed. This method is called \textit{concatenative speech synthesis}, and despite its relative simplicity, there is a limit to its realism\footnote{An example of this is a generic answer phone message, where the number you've called is read out one numeral at a time. The system is unable to mimic realistic intonation, since it does not know where in the sequence of numbers each numeral is placed. A human would read the last number with a downward intonation to indicate finality, or group shorter sequences of numbers together by speaking them in quick succession with pauses in between.}\cite{shadle2002prospects}. For this reason, more research is going into \textit{articulatory synthesis} which uses mathematical models of the vocal tract to imitate the way our bodies produce speech. This method is much more computationally expensive than the former, and current models are insufficient to produce natural sounding speech \cite{gray2005}. However, by incorporating more of the variables involved in human speech production into these models, with the help of physiological and acoustic data, there is no theoretical limit to the realism that we may be able to achieve with these artificial voices.